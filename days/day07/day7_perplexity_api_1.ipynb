{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cd2989fc-4ca9-4063-8f03-bff1b344033d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307de139-b9f2-4ac7-a83f-e9b4739629b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "PPLX_API_KEY = os.getenv(\"PPLX_API_KEY\")\n",
    "\n",
    "from llama_index.llms.perplexity import Perplexity\n",
    "\n",
    "llm = Perplexity(api_key=PPLX_API_KEY, model=\"sonar-pro\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1cd47-3d45-4657-964e-520ca4ed12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Perplexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d202586-7863-42f0-a065-f13811047709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ChatMessage class from the llama_index library.\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "# Create a list of dictionaries where each dictionary represents a chat message.\n",
    "# Each dictionary contains a 'role' key (e.g., system or user) and a 'content' key with the corresponding message.\n",
    "messages_dict = [\n",
    "    {\"role\": \"system\", \"content\": \"使用繁體中文回復使用者\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"可以告訴我特斯拉的股價嗎?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convert each dictionary in the list to a ChatMessage object using unpacking (**msg) in a list comprehension.\n",
    "messages = [ChatMessage(**msg) for msg in messages_dict]\n",
    "\n",
    "# Print the list of ChatMessage objects to verify the conversion.\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b830e-5f1a-4733-9793-c18fe2f77f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.chat(messages)\n",
    "print(f\"response type: {type(response)}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648fb79-03ed-4868-9df5-8e019f43ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_message(response):\n",
    "    rv = {}\n",
    "\n",
    "    messages = response.message\n",
    "    rv['role'] = messages.role\n",
    "    num_blocks = len(response.message.blocks)\n",
    "    blocks = []\n",
    "    for block_idx in range(num_blocks):\n",
    "        block = messages.blocks[block_idx]\n",
    "        blocks.append({\n",
    "            'block_type': block.block_type,\n",
    "            'text': block.text\n",
    "        })\n",
    "    rv['blocks'] = blocks\n",
    "    return rv\n",
    "\n",
    "def get_response_raw(response):\n",
    "    rv = {}\n",
    "\n",
    "    raw = response.raw  # dictionary\n",
    "    rv['model'] = raw['model']\n",
    "    rv['num_urls'] = len(raw['citations'])\n",
    "    rv['search_results'] = raw['search_results']  # 'title', 'url', 'date', last_updated, snippet\n",
    "    rv['urls'] = raw['citations']\n",
    "    return rv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7454264-ac5d-4180-9e73-c34980c0282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b407398-caf4-4d09-b53f-31c57b241b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = get_response_message(response)\n",
    "rv['blocks'][0]['text'].replace('\\n', '').split('。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5aaf1f-207c-4844-ac34-654c0a175dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response_raw(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1924bf-0d59-4a4a-81f2-22e1997becd6",
   "metadata": {},
   "source": [
    "# unstructured fact check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8b5f0-dfc5-4635-aa35-07a78378733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a professional fact-checker with extensive research capabilities. \"\n",
    "    \"Your task is to evaluate claims or articles for factual accuracy. \"\n",
    "    \"Focus on identifying false, misleading, or unsubstantiated claims.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e0a24-3e7d-4c1b-8c6c-fd11617cdbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14f1a6-3604-427f-83a9-b5b5fe75c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目前還是假新聞，五年後不知道\n",
    "text = (\n",
    "    \"特斯拉已經漲到1700美元，手握 280 股的投資人財富自由啦！\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c295dfc-36df-4c30-af36-d089583f80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"Fact check the following text and identify any false or misleading claims:\\n\\n{text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4e0b1-76ae-42ba-a4bb-3c49bb225844",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c29992-ff48-4ddf-98e7-1676b87fb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_dict = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Fact check the following text and identify any false or misleading claims:\\n\\n{text}\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convert each dictionary in the list to a ChatMessage object using unpacking (**msg) in a list comprehension.\n",
    "messages = [ChatMessage(**msg) for msg in messages_dict]\n",
    "\n",
    "# Print the list of ChatMessage objects to verify the conversion.\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4624f95-2cf0-4426-aae7-f210859f13da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.chat(messages)\n",
    "print(f\"response type: {type(response)}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9df718-f9f9-466d-9b85-aab2ec735121",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response_raw(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21af3ae-cee1-408e-ae2b-14fae184d792",
   "metadata": {},
   "source": [
    "# # structured fact check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c868c9-0811-4d3f-be77-00fa0434cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"Model for representing a single claim and its fact check.\"\"\"\n",
    "    claim: str = Field(description=\"The specific claim extracted from the text\")\n",
    "    rating: str = Field(description=\"Rating of the claim: TRUE, FALSE, MISLEADING, or UNVERIFIABLE\")\n",
    "    explanation: str = Field(description=\"Detailed explanation with supporting evidence\")\n",
    "    sources: List[str] = Field(description=\"List of sources used to verify the claim\")\n",
    "\n",
    "\n",
    "class FactCheckResult(BaseModel):\n",
    "    \"\"\"Model for the complete fact check result.\"\"\"\n",
    "    overall_rating: str = Field(description=\"Overall rating: MOSTLY_TRUE, MIXED, or MOSTLY_FALSE\")\n",
    "    summary: str = Field(description=\"Brief summary of the overall findings\")\n",
    "    claims: List[Claim] = Field(description=\"List of specific claims and their fact checks\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e50c659b-ed43-4853-8bd5-905686cf713e",
   "metadata": {},
   "source": [
    "from llama_index.llms.openai_like import OpenAILike  # pip install llama-index-llms-openai-like\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "llm = OpenAILike(\n",
    "    model=\"sonar-pro\",\n",
    "    api_base=\"https://api.perplexity.ai\",\n",
    "    api_key=PPLX_API_KEY,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "extra_body = {\n",
    "    \"response_format\": {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\"schema\": FactCheckResult.model_json_schema()},\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b01964-7db7-4917-acf3-76a8a1c1367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Perplexity(\n",
    "    api_key=PPLX_API_KEY,\n",
    "    model=\"sonar-pro\",\n",
    "    temperature=0.0,\n",
    "    additional_kwargs={\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\"schema\": FactCheckResult.model_json_schema()},\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d88a8-f912-4847-8d44-83e149e27413",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_dict = [\n",
    "    {\"role\": \"system\", \"content\": \"你是專業事實查核助手，只能輸出 JSON。\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"請檢查以下句子：地球是平的\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convert each dictionary in the list to a ChatMessage object using unpacking (**msg) in a list comprehension.\n",
    "messages = [ChatMessage(**msg) for msg in messages_dict]\n",
    "\n",
    "# Print the list of ChatMessage objects to verify the conversion.\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef442e5-c296-479a-a071-0e22341efb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.chat(\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7c447-3b57-404b-9007-b7d48d30fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfac81d-3eca-411a-a1a5-ed472867f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response_raw(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0aaece-337f-4308-a967-0aa9c642f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_dict = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Fact check the following text and identify any false or misleading claims:\\n\\n{text}\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convert each dictionary in the list to a ChatMessage object using unpacking (**msg) in a list comprehension.\n",
    "messages = [ChatMessage(**msg) for msg in messages_dict]\n",
    "\n",
    "# Print the list of ChatMessage objects to verify the conversion.\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1440803a-5433-4c56-ade2-6846080562d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = llm.chat(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60729785-40ad-4785-b37d-60ca46ed67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.message.blocks[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c70fe-fc1f-42c9-a770-97429f893854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag30",
   "language": "python",
   "name": "rag30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

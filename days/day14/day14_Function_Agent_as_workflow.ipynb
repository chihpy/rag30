{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9857c3-e79b-4f0e-a13e-a874394f2746",
   "metadata": {},
   "source": [
    "# 2. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147a129-1f8d-41e5-bf59-22a83898e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "from llama_index.core.workflow import Event\n",
    "from typing import Any, List\n",
    "from llama_index.core.llms.function_calling import FunctionCallingLLM\n",
    "from llama_index.core.memory import Memory\n",
    "from llama_index.core.tools import ToolSelection, ToolOutput\n",
    "\n",
    "from llama_index.core.tools.types import BaseTool\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d281e5-eec8-4838-a818-321ea5ffa816",
   "metadata": {},
   "source": [
    "# 3. event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1eaf60-0b11-408a-815e-9bc998c02a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEvent(Event):\n",
    "    input: list[ChatMessage]\n",
    "\n",
    "class ToolCallEvent(Event):\n",
    "    tool_calls: list[ToolSelection]\n",
    "\n",
    "class FunctionOutputEvent(Event):\n",
    "    output: ToolOutput\n",
    "\n",
    "class StreamEvent(Event):\n",
    "    msg: ChatMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821224d-b3b3-48ca-8c19-306f8ded54b2",
   "metadata": {},
   "source": [
    "# 4. Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfbe98-7a7c-4d9c-9f8a-55f1f71ab31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionCallingAgent(Workflow):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args: Any,\n",
    "        llm: FunctionCallingLLM | None = None,\n",
    "        tools: List[BaseTool] | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tools = tools or []\n",
    "\n",
    "        self.llm = llm or OpenAI()\n",
    "        assert self.llm.metadata.is_function_calling_model\n",
    "\n",
    "    @step\n",
    "    async def prepare_chat_history(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> InputEvent:\n",
    "        # clear sources\n",
    "        await ctx.store.set(\"sources\", [])\n",
    "\n",
    "        # check if memory is setup\n",
    "        memory = await ctx.store.get(\"memory\", default=None)\n",
    "        if not memory:\n",
    "            #memory = ChatMemoryBuffer.from_defaults(llm=self.llm)\n",
    "            memory = Memory.from_defaults(token_limit=40000)\n",
    "\n",
    "        # get user input\n",
    "        user_input = ev.input\n",
    "        user_msg = ChatMessage(role=\"user\", content=user_input)\n",
    "        memory.put(user_msg)\n",
    "\n",
    "        # get chat history\n",
    "        chat_history = memory.get()\n",
    "\n",
    "        # update context\n",
    "        await ctx.store.set(\"memory\", memory)\n",
    "\n",
    "        return InputEvent(input=chat_history)\n",
    "\n",
    "    @step\n",
    "    async def handle_llm_input(\n",
    "        self, ctx: Context, ev: InputEvent\n",
    "    ) -> ToolCallEvent | StopEvent:\n",
    "        chat_history = ev.input\n",
    "\n",
    "        # stream the response\n",
    "        #response_stream = await self.llm.astream_chat_with_tools(\n",
    "        #    self.tools, chat_history=chat_history\n",
    "        #)\n",
    "        #async for response in response_stream:\n",
    "        #    ctx.write_event_to_stream(StreamEvent(delta=response.delta or \"\"))\n",
    "        response = await self.llm.achat_with_tools(\n",
    "            self.tools, chat_history=chat_history\n",
    "        )\n",
    "        ctx.write_event_to_stream(StreamEvent(msg=response.message))\n",
    "\n",
    "        # save the final response, which should have all content\n",
    "        memory = await ctx.store.get(\"memory\")\n",
    "        memory.put(response.message)\n",
    "        await ctx.store.set(\"memory\", memory)\n",
    "\n",
    "        # get tool calls\n",
    "        tool_calls = self.llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )  # 如果這邊沒有 tool calls 回傳就會是 []\n",
    "\n",
    "        if not tool_calls:\n",
    "            sources = await ctx.store.get(\"sources\", default=[])\n",
    "            return StopEvent(\n",
    "                result={\"response\": response, \"sources\": [*sources]}\n",
    "            )\n",
    "        else:\n",
    "            return ToolCallEvent(tool_calls=tool_calls)\n",
    "\n",
    "    @step\n",
    "    async def handle_tool_calls(\n",
    "        self, ctx: Context, ev: ToolCallEvent\n",
    "    ) -> InputEvent:\n",
    "        tool_calls = ev.tool_calls  # model 要 call 的 tool\n",
    "        tools_by_name = {tool.metadata.get_name(): tool for tool in self.tools}  # 可以使用的 tool\n",
    "\n",
    "        tool_msgs = []\n",
    "        sources = await ctx.store.get(\"sources\", default=[])\n",
    "\n",
    "        # call tools -- safely!\n",
    "        for tool_call in tool_calls:\n",
    "            tool = tools_by_name.get(tool_call.tool_name)\n",
    "            additional_kwargs = {\n",
    "                \"tool_call_id\": tool_call.tool_id,\n",
    "                \"name\": tool.metadata.get_name(),\n",
    "            }\n",
    "            if not tool:\n",
    "                tool_msgs.append(\n",
    "                    ChatMessage(\n",
    "                        role=\"tool\",\n",
    "                        content=f\"Tool {tool_call.tool_name} does not exist\",\n",
    "                        additional_kwargs=additional_kwargs,\n",
    "                    )\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                tool_output = tool(**tool_call.tool_kwargs)\n",
    "                sources.append(tool_output)\n",
    "                tool_msgs.append(\n",
    "                    ChatMessage(\n",
    "                        role=\"tool\",\n",
    "                        content=tool_output.content,\n",
    "                        additional_kwargs=additional_kwargs,\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tool_msgs.append(\n",
    "                    ChatMessage(\n",
    "                        role=\"tool\",\n",
    "                        content=f\"Encountered error in tool call: {e}\",\n",
    "                        additional_kwargs=additional_kwargs,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # update memory\n",
    "        memory = await ctx.store.get(\"memory\")\n",
    "        for msg in tool_msgs:\n",
    "            memory.put(msg)\n",
    "\n",
    "        await ctx.store.set(\"sources\", sources)\n",
    "        await ctx.store.set(\"memory\", memory)\n",
    "\n",
    "        chat_history = memory.get()\n",
    "        return InputEvent(input=chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382e398-79c2-4d4b-8f5e-2ccb1eafae9e",
   "metadata": {},
   "source": [
    "# 5. workflow VIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8eaea2-17f4-42b6-833a-9c671dfcad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_all_possible_flows(\n",
    "    FunctionCallingAgent, filename=\"day14_FunctionCallingAgent.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d7f30-2abf-4d71-90e3-49233b71b8d9",
   "metadata": {},
   "source": [
    "# 6. tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214dc41-e998-4df2-89e8-b9d318ff3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.tavily_research.base import TavilyToolSpec\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "tavily_tool = TavilyToolSpec(\n",
    "    api_key=TAVILY_API_KEY,\n",
    ")\n",
    "tools = tavily_tool.to_tool_list()\n",
    "# 把工具轉成文字\n",
    "tool_descs = []\n",
    "for tool in tools:\n",
    "    tool_descs.append(f\"{tool.metadata.name}: {tool.metadata.description}\")\n",
    "\n",
    "tools_str = \"\\n\".join(tool_descs)\n",
    "tools_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b00e67-4471-4b39-aea9-d4ef272495e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tools_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959d158-13bc-4e83-84b7-3370d59bfc9b",
   "metadata": {},
   "source": [
    "# 7. init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51360abb-5258-4a77-bf9b-6876c0bfadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-5-mini\", streamimg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db35213-5537-4ff3-a205-9fe3bc6276c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent(\n",
    "    llm=OpenAI(model=\"gpt-5-mini\", streamimg=False), tools=tools, timeout=120, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1163b5-10db-4b3f-a9fc-45a1b11d5785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836273c-dc6d-44f8-a97a-7a3b75598b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = await agent.run(input=\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefa4e4-b87d-4e22-b407-88812b418a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c83577-fe15-4d3e-846a-aa464b8aafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = await agent.run(input=\"幫我查一下現在及時的特斯拉股價(美金)\")\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50f5c6-88e5-46e3-8660-a52ca3e74fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag30",
   "language": "python",
   "name": "rag30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

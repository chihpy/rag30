{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784f7d2-b734-494e-8eed-4f1b45af4415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d48d6-4c9d-4c47-85dc-f9abab8c5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instrumentation\n",
    "from llama_index.core.instrumentation import get_dispatcher\n",
    "from llama_index.core.instrumentation.span_handlers import SimpleSpanHandler\n",
    "\n",
    "# root dispatcher\n",
    "root_dispatcher = get_dispatcher()\n",
    "\n",
    "# register span handler\n",
    "simple_span_handler = SimpleSpanHandler()\n",
    "root_dispatcher.add_span_handler(simple_span_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff5132-d809-407b-8276-f34f8416235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env and langfuse\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langfuse import get_client\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "langfuse = get_client()\n",
    "\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "\n",
    "# Initialize LlamaIndex instrumentation\n",
    "LlamaIndexInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d47f8-4a5f-4cc0-8c9c-e0de8a4a45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents\n",
    "from llama_index.core import Document\n",
    "\n",
    "text_list = [\n",
    "    'Langfuse is an open source LLM engineering platform to help teams collaboratively debug, analyze and iterate on their LLM Applications. '\n",
    "    'With the Langfuse integration, you can track and monitor performance, traces, and metrics of your LlamaIndex application.' \n",
    "    'Detailed traces of the context augmentation and the LLM querying processes are captured and can be inspected directly in the Langfuse UI.',\n",
    "    \n",
    "    'Langfuse 真香',\n",
    "    \n",
    "    'The instrumentation module (available in llama-index v0.10.20 and later) is meant to replace the legacy callbacks module.',\n",
    "    \n",
    "    'Listed below are the core classes as well as their brief description of the instrumentation module: '\n",
    "    'Event — represents a single moment in time that a certain occurrence took place within the execution of the application’s code.'\n",
    "    'EventHandler — listen to the occurrences of Event’s and execute code logic at these moments in time.'\n",
    "    'Span — represents the execution flow of a particular part in the application’s code and thus contains Event’s.'\n",
    "    'SpanHandler — is responsible for the entering, exiting, and dropping (i.e., early exiting due to error) of Span’s.'\n",
    "    'Dispatcher — emits Event’s as well as signals to enter/exit/drop a Span to the appropriate handlers.',\n",
    "]\n",
    "documents = [Document(text=t) for t in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d88c9-5b49-422f-b453-65c881667eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model=\"gpt-5-mini\", temperature=0.0)\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "\n",
    "query = '什麼是 LlamaIndex 的instrumentation module?'\n",
    "with langfuse.start_as_current_span(name=\"notebook_test\") as span:\n",
    "    response = query_engine.query(query)\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea3695-ac6c-434a-bca2-8d62fb24b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_span_handler.print_trace_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4685bf1-ed83-49d2-aaa8-fe3c5989e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065e961-b660-4818-afa2-9ca272f0d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('trace.json', 'w') as f:\n",
    "    json.dump(json.loads(tree.to_json()), f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d427c-7892-4f71-8751-fb58e68142b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb94c1-668c-4108-9a87-8fa88bfad464",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng trace.dot -o trace.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac23bee-4f4f-4be0-9487-440eb31fd43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag30",
   "language": "python",
   "name": "rag30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

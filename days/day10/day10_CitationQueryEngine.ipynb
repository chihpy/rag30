{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751f0a5-6f6e-42aa-9892-44ac9a51ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-index-utils-workflow\n",
    "# TAVILY_API_KEY, OPENAI_API_KEY\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca08d3-5fd2-4781-bc39-28b7dc830ca5",
   "metadata": {},
   "source": [
    "## 3. Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641dc83c-4a44-4e8e-8f06-19d1c360eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "from llama_index.core.schema import Document, NodeWithScore\n",
    "\n",
    "class SearchEvent(Event):\n",
    "    \"\"\"Result of travily search\"\"\"\n",
    "\n",
    "    docs: list[Document]\n",
    "\n",
    "\n",
    "class CreateCitationsEvent(Event):\n",
    "    \"\"\"Add citations to the nodes.\"\"\"\n",
    "\n",
    "    nodes: list[NodeWithScore]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270f4db-ab9d-4da8-bf0b-2ea01d2a4214",
   "metadata": {},
   "source": [
    "## 4. vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0386fac-6641-4951-a305-fad5fe62f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CITATION_QA_TEMPLATE, CITATION_REFINE_TEMPLATE, \n",
    "# DEFAULT_CITATION_CHUNK_SIZE = 512\n",
    "# DEFAULT_CITATION_CHUNK_OVERLAP = 20\n",
    "\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "CITATION_QA_TEMPLATE_EN = PromptTemplate(\n",
    "    \"Please provide an answer based solely on the provided sources. \"\n",
    "    \"When referencing information from a source, \"\n",
    "    \"cite the appropriate source(s) using their corresponding numbers. \"\n",
    "    \"Every answer should include at least one source citation. \"\n",
    "    \"Only cite a source when you are explicitly referencing it. \"\n",
    "    \"If none of the sources are helpful, you should indicate that. \"\n",
    "    \"For example:\\n\"\n",
    "    \"Source 1:\\n\"\n",
    "    \"The sky is red in the evening and blue in the morning.\\n\"\n",
    "    \"Source 2:\\n\"\n",
    "    \"Water is wet when the sky is red.\\n\"\n",
    "    \"Query: When is water wet?\\n\"\n",
    "    \"Answer: Water will be wet when the sky is red [2], \"\n",
    "    \"which occurs in the evening [1].\\n\"\n",
    "    \"Now it's your turn. Below are several numbered sources of information:\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "CITATION_QA_TEMPLATE = PromptTemplate(\n",
    "    \"請僅根據所提供的來源回答問題。\"\n",
    "    \"在引用某個來源的資訊時，\"\n",
    "    \"請使用對應的編號來標註來源。\"\n",
    "    \"每個答案都必須至少包含一個來源的引用。\"  # 答案 / 陳述句\n",
    "    \"僅在明確引用該來源時才標註來源。\"\n",
    "    \"如果沒有任何來源有幫助，你應該指出這一點。\"  # 所以其實自帶了 filter\n",
    "    \"例如：\\n\"\n",
    "    \"來源 1:\\n\"\n",
    "    \"如果一隻土撥鼠會丟木頭，那牠能丟的木頭量，就等於「一隻會丟木頭的土撥鼠所能丟的木頭量」。\\n\"\n",
    "    \"來源 2:\\n\"\n",
    "    \"哪有土撥鼠真的會丟木頭。\\n\"\n",
    "    \"問題：一隻土撥鼠如果會丟木頭，那牠能丟多少木頭？\\n\"\n",
    "    \"答案：一般來說，土撥鼠其實並不會真的丟木頭 [2]。\"\n",
    "    \"不過如果牠真的會丟木頭，那牠能丟的數量，就等於一隻會丟木頭的土撥鼠所能丟的數量 [1]。\\n\"\n",
    "    \"現在輪到你了。以下是數個已編號的資訊來源：\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"問題：{query_str}\\n\"\n",
    "    \"答案：\"\n",
    ")\n",
    "\n",
    "CITATION_REFINE_TEMPLATE_EN = PromptTemplate(\n",
    "    \"Please provide an answer based solely on the provided sources. \"\n",
    "    \"When referencing information from a source, \"\n",
    "    \"cite the appropriate source(s) using their corresponding numbers. \"\n",
    "    \"Every answer should include at least one source citation. \"\n",
    "    \"Only cite a source when you are explicitly referencing it. \"\n",
    "    \"If none of the sources are helpful, you should indicate that. \"\n",
    "    \"For example:\\n\"\n",
    "    \"Source 1:\\n\"\n",
    "    \"The sky is red in the evening and blue in the morning.\\n\"\n",
    "    \"Source 2:\\n\"\n",
    "    \"Water is wet when the sky is red.\\n\"\n",
    "    \"Query: When is water wet?\\n\"\n",
    "    \"Answer: Water will be wet when the sky is red [2], \"\n",
    "    \"which occurs in the evening [1].\\n\"\n",
    "    \"Now it's your turn. \"\n",
    "    \"We have provided an existing answer: {existing_answer}\"\n",
    "    \"Below are several numbered sources of information. \"\n",
    "    \"Use them to refine the existing answer. \"\n",
    "    \"If the provided sources are not helpful, you will repeat the existing answer.\"\n",
    "    \"\\nBegin refining!\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_msg}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "CITATION_REFINE_TEMPLATE = PromptTemplate(\n",
    "    \"請僅根據所提供的來源來生成答案。\"\n",
    "    \"在引用來源中的資訊時，\"\n",
    "    \"請使用對應的來源編號進行標註。\"\n",
    "    \"每個答案都必須至少包含一個來源引用。\"\n",
    "    \"僅在你明確參考來源時才進行引用。\"\n",
    "    \"如果提供的來源沒有幫助，你應該直接重複既有的答案。\"\n",
    "    \"例如：\\n\"\n",
    "    \"來源 1：\\n\"\n",
    "    \"如果一隻土撥鼠會丟木頭，那牠能丟的木頭量，就等於「一隻會丟木頭的土撥鼠所能丟的木頭量」。\\n\"\n",
    "    \"來源 2：\\n\"\n",
    "    \"哪有土撥鼠真的會丟木頭。\\n\"\n",
    "    \"問題：一隻土撥鼠如果會丟木頭，那牠能丟多少木頭？\\n\"\n",
    "    \"答案：一般來說，土撥鼠其實並不會真的丟木頭 [2]。\"\n",
    "    \"不過如果牠真的會丟木頭，那牠能丟的數量，就等於一隻會丟木頭的土撥鼠所能丟的數量 [1]。\\n\"\n",
    "    \"現在輪到你了。\"\n",
    "    \"這裡有一個既有答案：{existing_answer}\\n\"\n",
    "    \"以下是幾個編號的資訊來源。\"\n",
    "    \"請使用這些來源來改進既有的答案。\"\n",
    "    \"如果來源沒有幫助，你就直接重複既有答案。\"\n",
    "    \"\\n開始改進！\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_msg}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"問題：{query_str}\\n\"\n",
    "    \"答案：\"\n",
    ")\n",
    "\n",
    "DEFAULT_CITATION_CHUNK_SIZE = 512\n",
    "DEFAULT_CITATION_CHUNK_OVERLAP = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d291f7-9dbe-4c0b-b0ae-85a227ec258b",
   "metadata": {},
   "source": [
    "## 4. Defining the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef30a82-41bf-4c63-9bec-3958a29ce76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    ")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.core.schema import (\n",
    "    MetadataMode,\n",
    "    NodeWithScore,\n",
    "    TextNode,\n",
    ")\n",
    "\n",
    "from llama_index.core.response_synthesizers import (\n",
    "    ResponseMode,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "\n",
    "from typing import Union, List\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from llama_index.tools.tavily_research.base import TavilyToolSpec\n",
    "\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "tavily_tool = TavilyToolSpec(\n",
    "    api_key=TAVILY_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff74ed8-8cf9-43ed-8bfd-1ba0b5f738f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitationQueryEngineWorkflow(Workflow):\n",
    "    @step\n",
    "    async def search(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> Union[SearchEvent, None]:\n",
    "        \"Entry point for RAG, triggered by a StartEvent with `query`.\"\n",
    "        query = ev.get(\"query\")\n",
    "        if not query:\n",
    "            return None\n",
    "\n",
    "        print(f\"Query the tavily with: {query}\")\n",
    "\n",
    "        # store the query in the global context\n",
    "        await ctx.store.set(\"query\", query)\n",
    "\n",
    "        docs = tavily_tool.search(query, max_results=3)\n",
    "        print(f\"get {len(docs)} docs.\")\n",
    "        return SearchEvent(docs=docs)\n",
    "\n",
    "    @step\n",
    "    async def create_citation_nodes(\n",
    "        self, ev: SearchEvent\n",
    "    ) -> CreateCitationsEvent:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            List[NodeWithScore]: A list of NodeWithScore objects, where each object\n",
    "            represents a smaller chunk of the original docs, labeled as a source.\n",
    "        \"\"\"\n",
    "        docs = ev.docs\n",
    "\n",
    "        nodes: List[NodeWithScore] = []\n",
    "\n",
    "        text_splitter = SentenceSplitter(\n",
    "            chunk_size=DEFAULT_CITATION_CHUNK_SIZE,\n",
    "            chunk_overlap=DEFAULT_CITATION_CHUNK_OVERLAP,\n",
    "        )\n",
    "\n",
    "        for doc in docs:\n",
    "            text_chunks = text_splitter.split_text(\n",
    "                doc.get_content(metadata_mode=MetadataMode.NONE)\n",
    "            )\n",
    "\n",
    "            for text_chunk in text_chunks:\n",
    "                text = f\"Source {len(nodes)+1}:\\n{text_chunk}\\n\"\n",
    "                \n",
    "                text_node = TextNode(\n",
    "                    text=text,\n",
    "                    metadata=doc.metadata,\n",
    "                    id_=doc.doc_id  # 注意：Document 有 doc_id 屬性\n",
    "                )\n",
    "\n",
    "                node = NodeWithScore(node=text_node, score=1.0)\n",
    "                nodes.append(node)\n",
    "        return CreateCitationsEvent(nodes=nodes)\n",
    "\n",
    "    @step\n",
    "    async def synthesize(\n",
    "        self, ctx: Context, ev: CreateCitationsEvent\n",
    "    ) -> StopEvent:\n",
    "        \"\"\"Return a streaming response using the retrieved nodes.\"\"\"\n",
    "        llm = OpenAI(model=\"gpt-5-mini\")\n",
    "        query = await ctx.store.get(\"query\", default=None)\n",
    "\n",
    "        synthesizer = get_response_synthesizer(\n",
    "            llm=llm,\n",
    "            text_qa_template=CITATION_QA_TEMPLATE,\n",
    "            refine_template=CITATION_REFINE_TEMPLATE,\n",
    "            response_mode=ResponseMode.COMPACT,\n",
    "            use_async=True,\n",
    "        )\n",
    "\n",
    "        response = await synthesizer.asynthesize(query, nodes=ev.nodes)\n",
    "        return StopEvent(result=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242609b0-f69d-4a8f-bf06-2957d4bd34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(\n",
    "    CitationQueryEngineWorkflow,\n",
    "    filename=\"Search_CitationQueryEngine_Workflow.html\",\n",
    "    # Optional, can limit long event names in your workflow\n",
    "    # Can help with readability\n",
    "    # max_label_length=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9eb17-a6ba-47fe-aadf-19a42774a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = CitationQueryEngineWorkflow()\n",
    "# Run a query\n",
    "query = '徵象(Signs)及症狀(Symptoms)之區別?'\n",
    "result = await w.run(query=query)\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2c650-2c96-44df-b6dd-25a0835fd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46baa2-e75d-4a28-bfb6-84f59aae0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.source_nodes[0].node.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d85d0-67b8-424c-8b47-f5651048464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.source_nodes[2].node.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d349bb-05c0-4fd1-b974-c100e543c638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag30",
   "language": "python",
   "name": "rag30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

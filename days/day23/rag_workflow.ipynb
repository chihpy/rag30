{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d18c501-a60c-4709-afc2-88a55ff7382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/run-llama/llama_index/blob/main/docs/examples/workflow/rag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5b1353-1a9c-408a-a9c5-c9fac60b42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d95659a-de9f-4240-ada4-9a44594b2576",
   "metadata": {},
   "source": [
    "# workflow design\n",
    "\n",
    "## rag + reranking consists of some clearly defined steps\n",
    "- Indexing data, creating an index\n",
    "- using that index + a query to retrieve relevant text chunks(node)\n",
    "- rerank the text retrieved node using the original query\n",
    "- synthesizing a final response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce419b1e-cce0-4686-812b-2b5a6c076430",
   "metadata": {},
   "source": [
    "# event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3c50da-cb93-42c5-9390-92976d0f6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Event\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "class RetrieverEvent(Event):\n",
    "    \"\"\"Result of running retrieval\"\"\"\n",
    "\n",
    "    nodes: list[NodeWithScore]\n",
    "\n",
    "\n",
    "class RerankEvent(Event):\n",
    "    \"\"\"Result of running reranking on retrieved nodes\"\"\"\n",
    "\n",
    "    nodes: list[NodeWithScore]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c15fc4-a6fa-4150-b7e5-2900606533af",
   "metadata": {},
   "source": [
    "# the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ac36e6-1830-42f1-835f-77face0cedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# pip install llama-index-vector-stores-faiss faiss-cpu\n",
    "import faiss\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "from llama_index.core.postprocessor.llm_rerank import LLMRerank\n",
    "\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775c47bf-c389-41e8-9f05-32ad0c436f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    @step\n",
    "    async def ingest(self, ctx: Context, ev: StartEvent) -> StopEvent | None:\n",
    "        \"\"\"document_dir, index_dir\"\"\"\n",
    "        document_dir = ev.get(\"document_dir\")\n",
    "        index_dir = ev.get(\"index_dir\")\n",
    "        if not index_dir:\n",
    "            # 如果沒有 index_dir 這條路就會直接走不通\n",
    "            # 所以 query 的時候預設是不用給 index_dir 的\n",
    "            return None\n",
    "        if not os.path.isdir(index_dir):\n",
    "            print(f'create index_dir: {index_dir}')\n",
    "            os.makedirs(index_dir)\n",
    "        if document_dir:\n",
    "            d = 1536\n",
    "            faiss_index = faiss.IndexFlatL2(d)\n",
    "            vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "            storage_context = StorageContext.from_defaults(\n",
    "                vector_store=vector_store\n",
    "            )\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents=documents,\n",
    "                embed_model=embed_model,\n",
    "                storage_context=storage_context,\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=index_dir)\n",
    "            print(\"Index built and persisted to:\", index_dir)\n",
    "        else:\n",
    "            print(f\"load index from: {index_dir}\")\n",
    "            # load index from disk\n",
    "            vector_store = FaissVectorStore.from_persist_dir(index_dir)\n",
    "            storage_context = StorageContext.from_defaults(\n",
    "                vector_store=vector_store, persist_dir=index_dir\n",
    "            )\n",
    "            index = load_index_from_storage(storage_context=storage_context)\n",
    "        return StopEvent(result=index)\n",
    "\n",
    "    @step\n",
    "    async def retrieve(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> RetrieverEvent | None:\n",
    "        \"Entry point for RAG, triggered by a StartEvent with `query`.\"\n",
    "        query = ev.get(\"query\")\n",
    "        index = ev.get(\"index\")\n",
    "\n",
    "        if not query:\n",
    "            return None\n",
    "\n",
    "        print(f\"Query the database with: {query}\")\n",
    "\n",
    "        # store the query in the global context\n",
    "        await ctx.store.set(\"query\", query)\n",
    "\n",
    "        # get the index from the global context\n",
    "        if index is None:\n",
    "            print(\"Index is empty, load some documents before querying!\")\n",
    "            return None\n",
    "\n",
    "        retriever = index.as_retriever(similarity_top_k=8)\n",
    "        nodes = await retriever.aretrieve(query)\n",
    "        print(f\"Retrieved {len(nodes)} nodes.\")\n",
    "        \n",
    "        retrieved_nodes = []\n",
    "        for node in nodes:\n",
    "            rv = {\n",
    "                'id': node.id_,\n",
    "                'text': node.text,\n",
    "                'score': node.score\n",
    "            }\n",
    "            retrieved_nodes.append(rv)\n",
    "        await ctx.store.set(\"retrieved_nodes\", retrieved_nodes)\n",
    "        return RetrieverEvent(nodes=nodes)\n",
    "\n",
    "    @step\n",
    "    async def rerank(self, ctx: Context, ev: RetrieverEvent) -> RerankEvent:\n",
    "        # Rerank the nodes\n",
    "        ranker = LLMRerank(\n",
    "            choice_batch_size=5, top_n=3, llm=OpenAI(model=\"gpt-4o-mini\")\n",
    "        )\n",
    "        print(await ctx.store.get(\"query\", default=None), flush=True)\n",
    "        new_nodes = ranker.postprocess_nodes(\n",
    "            ev.nodes, query_str=await ctx.store.get(\"query\", default=None)\n",
    "        )\n",
    "        print(f\"Reranked nodes to {len(new_nodes)}\")\n",
    "        reranked_nodes = []\n",
    "        for node in new_nodes:\n",
    "            rv = {\n",
    "                'id': node.id_,\n",
    "                'text': node.text,\n",
    "                'score': node.score\n",
    "            }\n",
    "            reranked_nodes.append(rv)\n",
    "        await ctx.store.set(\"reranked_nodes\", reranked_nodes)\n",
    "        return RerankEvent(nodes=new_nodes)\n",
    "\n",
    "    @step\n",
    "    async def synthesize(self, ctx: Context, ev: RerankEvent) -> StopEvent:\n",
    "        \"\"\"Return a streaming response using reranked nodes.\"\"\"\n",
    "        llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        summarizer = CompactAndRefine(llm=llm, streaming=False, verbose=True)\n",
    "        query = await ctx.store.get(\"query\", default=None)\n",
    "        response = await summarizer.asynthesize(query, nodes=ev.nodes)\n",
    "        retrieved_nodes = await ctx.store.get(\"retrieved_nodes\", default=None)\n",
    "        reranked_nodes = await ctx.store.get(\"reranked_nodes\", default=None)\n",
    "        rv = {\n",
    "            'query': query,\n",
    "            'response': response,\n",
    "            'retrieved_nodes': retrieved_nodes,\n",
    "            'reranked_nodes': reranked_nodes,\n",
    "        }\n",
    "        return StopEvent(result=rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38111b22-4e54-48e8-8da9-b5c856448d48",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75016032-1166-46ff-ae88-7eadfe51d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag_flow_all_self.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "# Draw all\n",
    "draw_all_possible_flows(RAGWorkflow, filename=\"rag_flow_all_self.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77faf0-7c88-432d-9c96-cb4a52e972c2",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84b8e7f1-6f9c-4f8c-b1f1-ad4b31d695a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load index from: storage\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from storage/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from storage/index_store.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: file:///home/poyuan/workspace/rag30/days/day23/rag_flow_all_self.html: Failed to find default application for content type ‘text/html’\n",
      "/home/poyuan/miniconda3/envs/rag30/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow()\n",
    "index_dir = 'storage'\n",
    "# Ingest the documents\n",
    "index = await w.run(index_dir=index_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed597e6-6e79-469d-9b53-bbed479ebb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query the database with: 什麼是深度學習的醍醐味?\n",
      "Retrieved 8 nodes.\n",
      "什麼是深度學習的醍醐味?\n",
      "Reranked nodes to 3\n",
      "深度學習的醍醐味在於面對模型訓練過程中的焦躁與迷茫，尤其是在等待人工智慧訓練結果和調整參數的過程中。這種不確定性和挑戰感是學習過程的一部分，讓學習者體驗到模型訓練的真實感受。\n"
     ]
    }
   ],
   "source": [
    "result = await w.run(query=\"什麼是深度學習的醍醐味?\", index=index)\n",
    "print(result['response'].response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4ffa2a-3f4e-4f92-8c0b-2af809974516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '18773912-c8b5-4fb4-8d4b-cb4e38758012',\n",
       "  'text': 'Cool上留言區的問題\\n那旁聽生\\n如果你想要加入NTU Cool的話\\n請直接寄信給助教\\n只要你寄信給助教說你要旁聽\\n我們都可以把你加入NTU Cool\\n那怎麼找到NTU Cool上面的留言區呢\\n假設你已經有選上這門課的話\\n那你就已經在NTU Cool裡面\\n那你在NTU Cool裡面點討論\\n然後你就可以看到9月12號上課\\n即時討論區這一個區域\\n然後你可以把你的問題留在這個地方\\n如果我有時間的話\\n會優先回答在討論區裡面的問題\\n那另外一個很重要的訊息要跟大家講的就是\\n因為呢\\n網路不是非常的穩定\\n所以直播是有可能斷線的\\n我們剛才測試的時候\\n其實直播就斷線了好幾次\\n那直播斷線有可能造成的問題就是\\n你可能會沒有辦法用同一個連結\\n再繼續看直播\\n所以假設我們遇到斷線的狀況\\n接下來我們的操作是\\n會開一個新的直播連結\\n然後透過NTU Cool寄給所有有修課的同學\\n但是假設你發現直播斷線\\n非常重要的一點就是\\n請勿驚慌 請勿驚慌',\n",
       "  'score': 1.8999251127243042},\n",
       " {'id': 'f1b8dce2-5b45-4ed8-b44d-0bf6e2306877',\n",
       "  'text': 'Cool寄給所有有修課的同學\\n但是假設你發現直播斷線\\n非常重要的一點就是\\n請勿驚慌 請勿驚慌 請勿驚慌\\n所有的課程統統都有錄影\\n所以直播斷線你就去做別的事情\\n反正所有的課程都是有錄影的\\n好接下來呢\\n我們講一下作業的規劃\\n我們這門課總共有十講\\n每一講都有一個對應的作業\\n那我把每一個作業的公告日期\\n還有截止日期都放在投影片上面\\n那基本上的每一個作業呢\\n都是留給大家三週的時間來完成\\n那唯一例外的呢\\n是前兩個作業\\n前兩個作業呢\\n我們特別把它的截止日期延後\\n延後到10月17號繳交\\n因為我知道說這門課\\n是很多不同學校的學生一起選修\\n那每一個學校加退選的時間都不一樣\\n所以大家加選到這門課的時間是不一樣的\\n所以前面幾個作業的日期延後\\n讓大家比較有時間可以完成\\n前面幾個作業\\n那另外一個要注意的事情就是\\n我們最後一個作業\\n作業時的截止日期是明年的1月9號\\n那我們要收到所有的作業以後\\n才能夠送出成績\\n所以送出成績的時間\\n一定是在1月9號之後\\n那我們目前預計1月12號把成績送出\\n那如果你有合理的理由\\n需要提早知道成績\\n那你可以跟助教講\\n因為我知道每一個學校呢\\n這個學期結束的時間是不一樣的\\n如果你需要提早知道成績\\n你可以跟助教講\\n那在12月19號作業時公告之後\\n我們可以優先改\\n需要提早知道成績的同學的作業\\n那每一個作業的繳交方式啊\\n是不一樣的\\n那這邊我列舉了每一個作業的繳交方式\\n那有一些作業呢\\n是透過NTU Cool這個平台繳交的\\n那會透過NTU Cool這個平台繳交的作業呢\\n就是出成選擇題\\n你就在NTU Cool那個平台上面\\n回答一些選擇題\\n就算是完成作業的繳交\\n那今天就會公告作業一\\n那等一下作業一的助教會告訴你說\\n怎麼在NTU Cool上面繳交作業\\n那除了透過NTU Cool繳交作業以外\\n我們還有另外一個繳交作業的系統\\n叫做JudgeBoi\\n什麼是JudgeB',\n",
       "  'score': 1.9280890226364136},\n",
       " {'id': 'f0e22525-58ae-443d-8c9f-024c8a93b944',\n",
       "  'text': 'code放在這頁投影片上面\\n那我們上課的方式呢\\n主要是以直播進行\\n那我會在那個台灣大學的新生教學館202\\n錄直播\\n然後所以如果你在現場看的話\\n你就是現場看那個直播的錄影\\n因為我們教室不大\\n所以鼓勵大家呢\\n其實可以在家裡看直播就好\\n那我們以後上課的時間\\n就是週五的下午2點20\\n那我們在週五下午要做的事情\\n是首先呢\\n我會先上課\\n那我通常上課上一個半小時到兩個小時左右\\n那上課的內容呢\\n會是以講解概念為主\\n但是有時候呢\\n我也會帶一些實作來作為輔助\\n那我上完課之後呢\\n接下來呢\\n助教會講解作業\\n那這個部分呢\\n通常是半個小時到一個小時左右\\n那大家要注意一下\\n我們下課的時間是不固定的\\n那我們就是2點20準時開始上課\\n那至於要講多久\\n取決於我們當週準備了多少的內容\\n那講完我們就下課\\n所以有時候可能會稍微提早下課\\n有時候可能會比較晚下課\\n但是因為課程的內容\\n通通都是會錄影的\\n所以假設說你有事情沒有辦法上這一門課\\n或這一門課持續的太長了\\n超過5點20\\n你有其他事情要去做\\n你都歡迎隨時可以離開\\n歡迎隨時可以中斷這個課程\\n因為反正所有課程的內容都會錄影\\n那最後也會上線\\n那我們上線的時間\\n以後預計就是我們週五錄影\\n然後預計在週一結束前\\n下一個週一結束前把影片上線\\n那如果在上課的時候\\n你對於上課的內容有問題的話\\n你可以在NTU Cool上面發問\\n那每次課程都會開一個對應的留言區\\n那我如果上課上到一段落有時間的話\\n就會優先回答放在NTU Cool上留言區的問題\\n那旁聽生\\n如果你想要加入NTU Cool的話\\n請直接寄信給助教\\n只要你寄信給助教說你要旁聽\\n我們都可以把你加入NTU Cool\\n那怎麼找到NTU Cool上面的留言區呢\\n假設你已經有選上這門課的話\\n那你就已經在NTU Cool裡面\\n那你在NTU',\n",
       "  'score': 1.9438271522521973},\n",
       " {'id': 'c9b0c2ac-d7b7-4183-9bcd-6c3d57686b61',\n",
       "  'text': 'to this course\\n這個也是VO3自己生成的\\n他產生的影片是帶有聲音的\\n那其他中文講課的聲音也通通都是合成的\\n我是用Eleven Labs這個軟體合成的\\n我是用Eleven Labs這個軟體合成的\\nEleven Labs做的事情就是\\n我給他一段我上課的錄影\\n他接下來就可以模仿我的聲音\\n我輸一段文字\\n他就用我的聲音把那段文字念出來\\n然後你看到的這個Talking head\\n就好像在一個房間裡面演講的這個頭像\\n是用一個叫Heygen的軟體生成的\\n那我做的事情就是給他一張我的照片和一段語音\\n他就可以自動讓照片中的人開始說話\\n那最後投影片的部分\\n也是人工智慧生成的\\n這是用一個叫做Genspark的平台生成的\\nGenspark其實是一個AI agent\\n那我們下週會講到AI agent的概念\\n那我在生成投影片的時候\\n我就是給他我們的課程說明\\n叫他把投影片做出來\\n他就產生投影片還有講稿\\n那我再把講稿丟給Eleven Labs\\n讓他產生聲音\\n所以剛才你看到的東西真的都是人工智慧生成的\\n而且我剛才並沒有用任何神奇的技術\\n這些都是你今天唾手可得的技術\\n好那我們就正式開始這門課\\n這門課叫做生成式人工智慧與機器學習導論\\n那我是李宏毅\\n那這是台灣大專院校人工智慧學程聯盟的課程\\n那這是我們的課程規劃\\n這門課我準備講十講\\n那每一講要講的日期\\n我都已經寫在這個投影片上面\\n那每一講要講的主題也都已經寫在投影片上\\n那我們這門課的前四講\\n會帶大家了解現有的生成式人工智慧\\n你會知道現有的生成式人工智慧\\n他是怎麼運作的\\n第五講到第八講\\n我會告訴大家\\n這些生成式人工智慧是怎麼被打造出來的\\n你也有機會自己訓練生成式人工智慧\\n那前八講呢\\n主要以文字互動為主\\n那第九講跟第十講\\n我們會講影像跟語音\\n那有關這門課的所有的資訊\\n包括上課錄影\\n課程投影片\\n還有作業的講解\\n你其實都可以在課程的公開網頁找到\\n那我把課程的公開網頁\\n放在這頁投影片上面\\n那我把QR',\n",
       "  'score': 1.9625170230865479},\n",
       " {'id': 'cb9fc3f6-be14-46c2-a608-03a6bfd9d99d',\n",
       "  'text': 'Cool那個平台上面\\n回答一些選擇題\\n就算是完成作業的繳交\\n那今天就會公告作業一\\n那等一下作業一的助教會告訴你說\\n怎麼在NTU Cool上面繳交作業\\n那除了透過NTU Cool繳交作業以外\\n我們還有另外一個繳交作業的系統\\n叫做JudgeBoi\\n什麼是JudgeBoi呢\\n就有一些作業不是選擇題\\n所以它的批改比較困難\\n我們會透過AI助教來批改\\n所以JudgeBoi就是背後有一個AI助教\\n在批改作業的平台\\n你把你的作業上傳到JudgeBoi\\n會由AI助教來批改你的作業\\n那這邊呢\\n告訴大家每一個作業預測的難度\\n從一顆星到三顆星\\n那一顆星代表說這個作業呢\\n預計在十幾分鐘內就可以完成\\n但我要強調一下\\n完成並不是說拿到滿分的成績\\n完成意思是說\\n你可以拿到一個及格的成績\\n假設滿分是十分的話\\n你可以拿到六分的成績\\n那如果兩顆星的作業代表呢\\n至少需要超過一個小時以上\\n才有辦法完成\\n三顆星代表說\\n可能需要好幾好多個小時\\n數個小時三四個小時\\n才有辦法達到及格的成績\\n那有一些作業呢\\n需要訓練模型\\n那也許還不是每位同學都知道\\n訓練模型是什麼意思\\n但你就質疑的說\\n有需要訓練模型的作業\\n就是特別花時間的作業\\n訓練模型就是一件非常花時間的事情\\n有一些作業呢\\n你訓練模型的時間\\n可能甚至長達三四個小時\\n有的同學會覺得說\\n這不就是跑一個城市嗎\\n跑一個城市居然要跑三四個小時\\n太荒謬了\\n所以過去有同學就跟我說\\n你怎麼可以把作業設計成這樣呢\\n為什麼作業要跑三個小時呢\\n我只允許這個作業三分鐘\\n就應該要跑完\\n我們有當然可以把這些特別花時間\\n需要特別花時間訓練的作業拿掉\\n但是我還是選擇在這門課裡面\\n保留那一些\\n需要一定訓練時間的作業\\n因為焦躁的等待人工智慧訓練的結果\\n迷茫的調參數\\n不',\n",
       "  'score': 1.9724153280258179},\n",
       " {'id': 'eba16e20-d000-4b3e-b05a-b1589f6b9fe9',\n",
       "  'text': '各位同學大家好 我們來上課吧\\n剛才只是用Google的VO3\\n這個可以生成影片的人工智慧\\n隨便生了一些影片\\n作為開場,我們現在來正式開始這門課\\n我們先把投影片開起來\\n歡迎來到這門超級有趣的課程\\n很高興能在這個AI大爆發的時代\\n跟大家一起學習\\n我們要一起走進最酷的AI時代\\n在開始之前,我想問問大家\\n有多少人已經在用ChatGPT了\\n我相信大部分同學都已經在用了\\n相信大家都已經感受到AI的厲害了\\n但是今天這門課\\n我們要做的事情會更有趣\\n那麼這門課到底要學什麼呢?\\n首先別以為只是學會用ChatGPT寫作業\\n我知道你們可能已經很會用了\\n這個課程不是要跟你講\\n你怎麼用這些工具\\n我們要做的是更深層的事情\\n我們要了解這些神奇工具背後的原理\\n他們到底是怎麼被打造出來的\\n以及如果你想要進一步善用\\n甚至讓這些工具變得更厲害\\n你還可以怎麼做\\n簡單來說\\n我們要從使用者變成理解者\\n甚至是創造者\\n那你可能會問\\n了解原理有什麼好處呢?\\n我現在不懂原理也能用得很好啊\\n這個問題問得很好\\n讓我用一個比喻來說明\\n現在的生成式AI超級強大\\n使用起來就像是編模數一樣\\n每個人突然都能變出神奇的效果\\n但是這裡有個關鍵的差別\\n如果你不懂原理\\n你依然能用這些工具\\n但你很容易把魔術錯誤的當作魔法\\n什麼意思呢?\\n魔術是有技巧有原理的\\n而魔法是神秘不可解釋的\\n當你把AI當作魔法來看\\n你可能會產生各種誤解\\n比如覺得AI全能或者害怕AI會取代所有人\\n但如果你懂得背後的原理\\n魔術就不再是魔法\\n你可以更清楚的看到魔術背後的技巧\\n甚至可以創造自己的魔術\\n接下來我們來談談這門課的定位\\n這是一門AI入門課\\n希望讓大家對AI有正確而且深入的認識\\n那麼什麼樣的同學適合來選修\\n我們這門課呢?',\n",
       "  'score': 1.9993680715560913},\n",
       " {'id': '8c34bf19-2fb0-4755-8b8b-86746a99481a',\n",
       "  'text': '像是預防針\\n幫助你在未來面對更大的挑戰\\n幫助你在未來面對挑戰的時候\\n做好心理準備\\n另外呢\\n鼓勵大家如果有空的話\\n可以先看一些線上的錄影進行預習\\n那假設你對於生成式AI一無所知的話\\n那你可以先看生成式AI導論2024的課程\\n那如果2024的課程看完\\n你想要進一步了解\\n這些AI是怎麼被訓練出來的\\n鼓勵你可以看機器學習2021\\n那不過這一堂門課呢\\n我們會從基礎開始講起\\n所以就算你沒有時間預習也無所謂\\n但是如果你能夠找到時間預習的話\\n未來上課你可以有更多的收穫',\n",
       "  'score': 2.008880615234375},\n",
       " {'id': 'e6955f99-8070-4c73-aa72-c338f2c2c1c2',\n",
       "  'text': '作業設計成這樣呢\\n為什麼作業要跑三個小時呢\\n我只允許這個作業三分鐘\\n就應該要跑完\\n我們有當然可以把這些特別花時間\\n需要特別花時間訓練的作業拿掉\\n但是我還是選擇在這門課裡面\\n保留那一些\\n需要一定訓練時間的作業\\n因為焦躁的等待人工智慧訓練的結果\\n迷茫的調參數\\n不知道會不會成功\\n這個就是人工智慧的醍醐味\\n所以大家需要學習\\n在迷茫中前進\\n這個就是模型的訓練\\n我們特別把這一部分保留在課程裡面\\n讓你體驗說\\n模型訓練不出來的焦躁\\n到底是什麼樣的感覺\\n而且我必須要強調啊\\n什麼三四個小時的等待訓練時間\\n真的不算什麼\\n我們過去有很多作業訓練時間都是\\n至少三天起跳\\n你要至少訓練三天\\n你才能夠拿到成績\\n那我知道說很多同學在做作業的時候\\n往往你都在實現\\n最後一天才開始做作業\\n但那一種啊\\n需要訓練三天以上的模型\\n你只在前一天才開始做作業\\n你是絕不可能完成的\\n這個時候我告訴你\\n你唯一可以做的事情\\n就是放棄這樣子\\n還好我們這堂課裡面呢\\n現在是沒有需要訓練一天以上的作業啦\\n我們把那種\\n特別需要花時間訓練的作業\\n還是拿掉了\\n只保留了需要訓練三四個小時的作業\\n但我只想要強調說\\n三四個小時的訓練時間\\n真的不算什麼\\n如果你要真正用大量的資料\\n大規模的訓練模型\\n訓練個數週\\n其實都是常見的事情\\n而這一些\\n需要一點訓練時間的作業\\n它的定位就像是預防針\\n幫助你在未來面對更大的挑戰\\n幫助你在未來面對挑戰的時候\\n做好心理準備\\n另外呢\\n鼓勵大家如果有空的話\\n可以先看一些線上的錄影進行預習\\n那假設你對於生成式AI一無所知的話\\n那你可以先看生成式AI導論2024的課程\\n那如果2024的課程看完\\n你想要進一步了解\\n這些AI是怎麼被訓練出來',\n",
       "  'score': 2.0310215950012207}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['retrieved_nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9be80e-293d-4fe9-ba4c-e4431040a510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e6955f99-8070-4c73-aa72-c338f2c2c1c2',\n",
       "  'text': '作業設計成這樣呢\\n為什麼作業要跑三個小時呢\\n我只允許這個作業三分鐘\\n就應該要跑完\\n我們有當然可以把這些特別花時間\\n需要特別花時間訓練的作業拿掉\\n但是我還是選擇在這門課裡面\\n保留那一些\\n需要一定訓練時間的作業\\n因為焦躁的等待人工智慧訓練的結果\\n迷茫的調參數\\n不知道會不會成功\\n這個就是人工智慧的醍醐味\\n所以大家需要學習\\n在迷茫中前進\\n這個就是模型的訓練\\n我們特別把這一部分保留在課程裡面\\n讓你體驗說\\n模型訓練不出來的焦躁\\n到底是什麼樣的感覺\\n而且我必須要強調啊\\n什麼三四個小時的等待訓練時間\\n真的不算什麼\\n我們過去有很多作業訓練時間都是\\n至少三天起跳\\n你要至少訓練三天\\n你才能夠拿到成績\\n那我知道說很多同學在做作業的時候\\n往往你都在實現\\n最後一天才開始做作業\\n但那一種啊\\n需要訓練三天以上的模型\\n你只在前一天才開始做作業\\n你是絕不可能完成的\\n這個時候我告訴你\\n你唯一可以做的事情\\n就是放棄這樣子\\n還好我們這堂課裡面呢\\n現在是沒有需要訓練一天以上的作業啦\\n我們把那種\\n特別需要花時間訓練的作業\\n還是拿掉了\\n只保留了需要訓練三四個小時的作業\\n但我只想要強調說\\n三四個小時的訓練時間\\n真的不算什麼\\n如果你要真正用大量的資料\\n大規模的訓練模型\\n訓練個數週\\n其實都是常見的事情\\n而這一些\\n需要一點訓練時間的作業\\n它的定位就像是預防針\\n幫助你在未來面對更大的挑戰\\n幫助你在未來面對挑戰的時候\\n做好心理準備\\n另外呢\\n鼓勵大家如果有空的話\\n可以先看一些線上的錄影進行預習\\n那假設你對於生成式AI一無所知的話\\n那你可以先看生成式AI導論2024的課程\\n那如果2024的課程看完\\n你想要進一步了解\\n這些AI是怎麼被訓練出來',\n",
       "  'score': 9.0},\n",
       " {'id': 'c9b0c2ac-d7b7-4183-9bcd-6c3d57686b61',\n",
       "  'text': 'to this course\\n這個也是VO3自己生成的\\n他產生的影片是帶有聲音的\\n那其他中文講課的聲音也通通都是合成的\\n我是用Eleven Labs這個軟體合成的\\n我是用Eleven Labs這個軟體合成的\\nEleven Labs做的事情就是\\n我給他一段我上課的錄影\\n他接下來就可以模仿我的聲音\\n我輸一段文字\\n他就用我的聲音把那段文字念出來\\n然後你看到的這個Talking head\\n就好像在一個房間裡面演講的這個頭像\\n是用一個叫Heygen的軟體生成的\\n那我做的事情就是給他一張我的照片和一段語音\\n他就可以自動讓照片中的人開始說話\\n那最後投影片的部分\\n也是人工智慧生成的\\n這是用一個叫做Genspark的平台生成的\\nGenspark其實是一個AI agent\\n那我們下週會講到AI agent的概念\\n那我在生成投影片的時候\\n我就是給他我們的課程說明\\n叫他把投影片做出來\\n他就產生投影片還有講稿\\n那我再把講稿丟給Eleven Labs\\n讓他產生聲音\\n所以剛才你看到的東西真的都是人工智慧生成的\\n而且我剛才並沒有用任何神奇的技術\\n這些都是你今天唾手可得的技術\\n好那我們就正式開始這門課\\n這門課叫做生成式人工智慧與機器學習導論\\n那我是李宏毅\\n那這是台灣大專院校人工智慧學程聯盟的課程\\n那這是我們的課程規劃\\n這門課我準備講十講\\n那每一講要講的日期\\n我都已經寫在這個投影片上面\\n那每一講要講的主題也都已經寫在投影片上\\n那我們這門課的前四講\\n會帶大家了解現有的生成式人工智慧\\n你會知道現有的生成式人工智慧\\n他是怎麼運作的\\n第五講到第八講\\n我會告訴大家\\n這些生成式人工智慧是怎麼被打造出來的\\n你也有機會自己訓練生成式人工智慧\\n那前八講呢\\n主要以文字互動為主\\n那第九講跟第十講\\n我們會講影像跟語音\\n那有關這門課的所有的資訊\\n包括上課錄影\\n課程投影片\\n還有作業的講解\\n你其實都可以在課程的公開網頁找到\\n那我把課程的公開網頁\\n放在這頁投影片上面\\n那我把QR',\n",
       "  'score': 8.0},\n",
       " {'id': 'f0e22525-58ae-443d-8c9f-024c8a93b944',\n",
       "  'text': 'code放在這頁投影片上面\\n那我們上課的方式呢\\n主要是以直播進行\\n那我會在那個台灣大學的新生教學館202\\n錄直播\\n然後所以如果你在現場看的話\\n你就是現場看那個直播的錄影\\n因為我們教室不大\\n所以鼓勵大家呢\\n其實可以在家裡看直播就好\\n那我們以後上課的時間\\n就是週五的下午2點20\\n那我們在週五下午要做的事情\\n是首先呢\\n我會先上課\\n那我通常上課上一個半小時到兩個小時左右\\n那上課的內容呢\\n會是以講解概念為主\\n但是有時候呢\\n我也會帶一些實作來作為輔助\\n那我上完課之後呢\\n接下來呢\\n助教會講解作業\\n那這個部分呢\\n通常是半個小時到一個小時左右\\n那大家要注意一下\\n我們下課的時間是不固定的\\n那我們就是2點20準時開始上課\\n那至於要講多久\\n取決於我們當週準備了多少的內容\\n那講完我們就下課\\n所以有時候可能會稍微提早下課\\n有時候可能會比較晚下課\\n但是因為課程的內容\\n通通都是會錄影的\\n所以假設說你有事情沒有辦法上這一門課\\n或這一門課持續的太長了\\n超過5點20\\n你有其他事情要去做\\n你都歡迎隨時可以離開\\n歡迎隨時可以中斷這個課程\\n因為反正所有課程的內容都會錄影\\n那最後也會上線\\n那我們上線的時間\\n以後預計就是我們週五錄影\\n然後預計在週一結束前\\n下一個週一結束前把影片上線\\n那如果在上課的時候\\n你對於上課的內容有問題的話\\n你可以在NTU Cool上面發問\\n那每次課程都會開一個對應的留言區\\n那我如果上課上到一段落有時間的話\\n就會優先回答放在NTU Cool上留言區的問題\\n那旁聽生\\n如果你想要加入NTU Cool的話\\n請直接寄信給助教\\n只要你寄信給助教說你要旁聽\\n我們都可以把你加入NTU Cool\\n那怎麼找到NTU Cool上面的留言區呢\\n假設你已經有選上這門課的話\\n那你就已經在NTU Cool裡面\\n那你在NTU',\n",
       "  'score': 6.0}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['reranked_nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02169f-a88f-4ac3-8daa-c2453114c356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag30",
   "language": "python",
   "name": "rag30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

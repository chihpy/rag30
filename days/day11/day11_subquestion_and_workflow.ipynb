{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e969d2aa-0a9d-48ef-a474-df23d892cc85",
   "metadata": {},
   "source": [
    "# part1: workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c38ef-1083-41f2-bb6c-7b8b751bf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Workflow\n",
    "from llama_index.core.workflow import step\n",
    "from llama_index.core.workflow import Event\n",
    "from llama_index.core.workflow import StartEvent\n",
    "from llama_index.core.workflow import StopEvent\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a64136-f3bb-4ecb-b98a-14782b9daf03",
   "metadata": {},
   "source": [
    "# event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd7f90-dc07-45a4-bb71-b342ec3a6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryEvent(Event):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class AnswerEvent(Event):\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c6531-91d4-40d6-9578-83e4f7210185",
   "metadata": {},
   "source": [
    "# workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc48d87-388c-447c-ac8f-618ac457b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubQuestionQueryEngine(Workflow):\n",
    "    @step\n",
    "    async def query(self, ctx: Context, ev: StartEvent) -> QueryEvent:\n",
    "        # Fake subquestions gen\n",
    "        FAKE_NUM_SUB_QUESTION = 5\n",
    "        sub_questions = [f'q{i}' for i in range(FAKE_NUM_SUB_QUESTION)]\n",
    "\n",
    "        # get num_question\n",
    "        num_question = len(sub_questions)\n",
    "        await ctx.store.set(\"num_question\", len(sub_questions))\n",
    "\n",
    "        for q in sub_questions:\n",
    "            #self.send_event(QueryEvent(question=question))\n",
    "            print(f\"send: {q}\")\n",
    "            ctx.send_event(QueryEvent(question=q))\n",
    "        return None\n",
    "\n",
    "    @step\n",
    "    async def sub_question(self, ctx: Context, ev: QueryEvent) -> AnswerEvent:\n",
    "        print(f\"Sub-question is {ev.question}\")\n",
    "        # get fake answer\n",
    "        answer = f\"answer of: {ev.question}\"\n",
    "        return AnswerEvent(question=ev.question, answer=answer)\n",
    "\n",
    "    @step\n",
    "    async def combine_answers(\n",
    "        self, ctx: Context, ev: AnswerEvent\n",
    "    ) -> StopEvent | None:\n",
    "        num_question = await ctx.store.get(\"num_question\")\n",
    "        # wait until we receive 3 events\n",
    "        result = ctx.collect_events(ev, [AnswerEvent] * num_question)\n",
    "        if result is None:\n",
    "            print('combine_answers output None')\n",
    "            return None\n",
    "\n",
    "        # do something with all {num_question} together\n",
    "        print(result)\n",
    "        return StopEvent(result=\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ae746-96aa-4d17-9af4-245f6337d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_all_possible_flows(\n",
    "    SubQuestionQueryEngine, filename=\"fake_sub_question_query_engine.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07986159-0ed5-4e44-affe-aa664b805ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = SubQuestionQueryEngine(timeout=10, verbose=False)\n",
    "result = await w.run()\n",
    "print('---')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c76b0-bb9c-4402-84ef-f814a0d5bfef",
   "metadata": {},
   "source": [
    "# part2: sub_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f4e0a-9647-42ee-9a7b-8ce0ddf53796",
   "metadata": {},
   "outputs": [],
   "source": [
    "qset = {\n",
    "  \"id\": \"113-1-1-med-surg\",\n",
    "  \"year\": \"113\",\n",
    "  \"time\": \"1\",\n",
    "  \"qid\": \"1\",\n",
    "  \"discipline\": \"內外科護理學\",\n",
    "  \"ans\": \"C\",\n",
    "  \"question\": \"有關多發性硬化症之診斷檢查，下列何者錯誤？\",\n",
    "  \"options\": {\n",
    "   \"A\": \"腦脊髓液分析可發現IgG抗體上升\",\n",
    "   \"B\": \"視覺誘發電位可觀察到受損的神經在傳導過程出現延遲和中斷\",\n",
    "   \"C\": \"超音波檢查可發現中樞神經系統髓鞘脫失\",\n",
    "   \"D\": \"核磁共振影像可用來確認多發性硬化症之斑塊\"\n",
    "  },\n",
    "  \"discipline_slug\": \"med-surg\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cd4c4-de3d-4ead-a309-5fab9fb9df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"以下為單選題，請從各選項中選擇最符合題意的答案：\\n題幹: {qset['question']}.\\n選項: \\nA: {qset['options']['A']}; B: {qset['options']['B']}; C: {qset['options']['C']}; D: {qset['options']['D']}.\"\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a9db4-cf48-4766-9dd0-9f9a2eaa4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_en = f\"\"\"Given a user question, output a list of relevant sub-questions, such that the answers to all the\n",
    "sub-questions put together will answer the question. \n",
    "Respond in pure JSON without any markdown, like this:\n",
    "{{\n",
    "    \"sub_questions\": [\n",
    "        \"What is the population of San Francisco?\",\n",
    "        \"What is the budget of San Francisco?\",\n",
    "        \"What is the GDP of San Francisco?\"\n",
    "    ]\n",
    "}}\n",
    "Here is the user question: {question}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52a834-525e-470c-8da1-d9e9f1fa8c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(prompt_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ae2b5-6395-4e95-b5ba-8ea09a3d926d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca63d03-ce81-4522-8111-ebecdaa97b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"給定一個使用者的問題，請輸出一系列相關的子問題，讓所有子問題的答案合在一起後，\n",
    "能完整回答該問題。\n",
    "請只用純 JSON 格式回應，不要包含任何 Markdown，例如：\n",
    "{{\n",
    "    \"sub_questions\": [\n",
    "        \"舊金山的人口是多少？\",\n",
    "        \"舊金山的預算是多少？\",\n",
    "        \"舊金山的 GDP 是多少？\"\n",
    "    ]\n",
    "}}\n",
    "以下是使用者的問題：{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d53f47-97b9-4e96-822c-17ec11aad9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054d540-68d2-4efc-af31-cb784e93d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e39c1-c08b-4863-9676-3b9520774c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-5-mini\",\n",
    "    temperature=0,\n",
    "    json_mode=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb7906-35d9-457c-ab81-ce1a1bebc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122513b9-f984-4536-9692-a526ed757736",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18aacb-54ee-4075-9f57-08d421065327",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0eee1f-0b3f-4905-9f8c-24778b17eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fe5aa-4da5-4112-b63f-31b884978aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57801ba9-19ca-447b-9763-dbc6f338feed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag30",
   "language": "python",
   "name": "rag30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
